# Paper Title: A Second Look on BASS - Boosting Abstractive Summarization with Unified Semantic Graphs
# Author: Osman Alperen Koras
# Affiliation: Institute for AI in Medicine (IKIM), University Medicine Essen
# Email: osman.koras@uni-due.de
# Date: 12.10.2023
#
# License: MIT
from __future__ import annotations

from abc import ABCMeta, abstractmethod

from stanza.protobuf import CoreNLP_pb2
from preprocessing import doc, usg


class Parser(metaclass=ABCMeta):
    @abstractmethod
    def parse(self, data: any) -> any:
        pass

    @abstractmethod
    def is_alive(self) -> bool:
        pass


class CoreNlpAnnotationParser(Parser):
    def __init__(self):
        pass

    def is_alive(self) -> bool:
        return True

    def parse(self, d: CoreNLP_pb2.Document) -> doc.Document:
        document: doc.Document = doc.Document(None)
        annotation: CoreNLP_pb2.Document = d

        for s in annotation.sentence:
            sentence = CoreNlpAnnotationParser.parse_sentence(document, s)
            document.sentences.append(sentence)

        for c in annotation.corefChain:
            cluster = doc.EntityCluster()
            for index, mention in enumerate(c.mention):
                entity = doc.Entity()
                entity.sentence = document.sentences[mention.sentenceIndex]
                entity.tokens = entity.sentence.tokens[mention.beginIndex:mention.endIndex]
                entity.root = entity.sentence.tokens[mention.headIndex]
                cluster.mentions.append(entity)
            cluster.representative = cluster.mentions[c.representative]
            document.entity_clusters.append(cluster)

        return document

    @staticmethod
    def parse_sentence(document: doc.Document, s: any) -> doc.Sentence:
        sentence = doc.Sentence(document)
        for i, t in enumerate(s.token):
            token = CoreNlpAnnotationParser.parse_token(t)
            token.index_in_sentence = i
            sentence.tokens.append(token)

        sentence.semantic_graph = CoreNlpAnnotationParser.parse_dependency_tree(sentence, s.enhancedPlusPlusDependencies)

        for token in sentence.tokens:
            if token.node.incoming_edges:
                token.dependency_head = token.node.incoming_edges[0].source.root
                token.dependency_relation = token.node.incoming_edges[0].relation
            token.dependency_children = [e.destination.tokens[0] for e in token.node.outgoing_edges]
            token.sentence = sentence

        return sentence

    @staticmethod
    def parse_token(t: any) -> doc.Token:
        token = doc.Token()
        token.text = t.originalText
        if t.value != t.originalText:
            print(f"\"{t.value}\" != \"{t.originalText}\"")
        token.xpos = t.pos
        return token

    @staticmethod
    def parse_dependency_tree(sentence: doc.Sentence, tree: any) -> usg.Graph:
        graph = usg.Graph()
        for n in tree.node:
            # The graphs generated by corenlp are sometimes erronous... and some nodes appear multiple times
            # they are meant to be a copy
            if sentence.tokens[n.index-1].node is None:
                node = CoreNlpAnnotationParser.parse_node(sentence, n)
                graph.nodes.append(node)

        graph.nodes.sort(key=lambda x: x.index)
        for e in tree.edge:
            edge = CoreNlpAnnotationParser.parse_edge(graph, e)
            graph.edges.append(edge)

        if tree.root:
            for index in tree.root:
                root_node = graph.nodes[index - 1]
                graph.add_edge(root_node, root_node, "ROOT")
        return graph

    @staticmethod
    def parse_node(sentence: doc.Sentence, n: any) -> usg.Node:
        node = usg.Node()
        node.index = n.index - 1
        node.root = sentence.tokens[node.index]
        node.root.copy_count = n.copyAnnotation
        node.tokens.append(node.root)
        node.root.node = node
        return node

    @staticmethod
    def parse_edge(graph, e):
        edge = usg.Edge()
        edge.source = graph.nodes[e.source - 1]
        edge.destination = graph.nodes[e.target - 1]
        edge.source.outgoing_edges.append(edge)
        edge.destination.incoming_edges.append(edge)
        edge.relation = e.dep
        edge.is_extra = e.isExtra
        return edge